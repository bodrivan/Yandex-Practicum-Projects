{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Основная-информация-о-данных\" data-toc-modified-id=\"Основная-информация-о-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Основная информация о данных</a></span></li><li><span><a href=\"#Удаление-лишних-данных\" data-toc-modified-id=\"Удаление-лишних-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Удаление лишних данных</a></span></li><li><span><a href=\"#Расчет-процента-токсичных-твитов\" data-toc-modified-id=\"Расчет-процента-токсичных-твитов-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Расчет процента токсичных твитов</a></span></li><li><span><a href=\"#Очистка,-лемматизация-текста\" data-toc-modified-id=\"Очистка,-лемматизация-текста-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Очистка, лемматизация текста</a></span></li><li><span><a href=\"#Разделение-на-выборки\" data-toc-modified-id=\"Разделение-на-выборки-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Разделение на выборки</a></span></li><li><span><a href=\"#Балансировка-классов\" data-toc-modified-id=\"Балансировка-классов-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Балансировка классов</a></span></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>TF-IDF</a></span></li><li><span><a href=\"#Промежуточый-вывод\" data-toc-modified-id=\"Промежуточый-вывод-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Промежуточый вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Решающее-дерево\" data-toc-modified-id=\"Решающее-дерево-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Решающее дерево</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Промежуточный-вывод\" data-toc-modified-id=\"Промежуточный-вывод-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Промежуточный вывод</a></span></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bodri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bodri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "nltk.download('stopwords') \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = '/Users/ivanbodrenkov/Yandex.Disk.localized/Яндекс Практикум/13. ML для текстов/Проект/toxic_comments.csv'\n",
    "path_2 = 'https://code.s3.yandex.net/datasets/toxic_comments.csv'\n",
    "path_3 = 'C:/Users/bodrenkov_ia/Desktop/Project/toxic_comments.csv'\n",
    "path_4 = '/datasets/toxic_comments.csv'\n",
    "path_5 = 'D:/Яндекс Диск/YandexDisk/Яндекс Практикум/13. ML для текстов/Проект/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(path_1):\n",
    "    data = pd.read_csv(path_1, sep = ',')\n",
    "elif os.path.exists(path_2):\n",
    "    data = pd.read_csv(path_2, sep = ',')\n",
    "elif os.path.exists(path_3):\n",
    "    data = pd.read_csv(path_3, sep = ',')\n",
    "elif os.path.exists(path_4):\n",
    "    data = pd.read_csv(path_4, sep = ',')\n",
    "elif os.path.exists(path_5):\n",
    "    data = pd.read_csv(path_5, sep = ',')\n",
    "else:\n",
    "    print('Что-то пошло не так!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_lemmatizer(text:pd.Series):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    wnt = WhitespaceTokenizer()\n",
    "    \n",
    "    return np.array([wnl.lemmatize(w) for w in wnt.tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    text = text.split()\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основная информация о данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление лишних данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = 'Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчет процента токсичных твитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токсичных твитов во всем датасете 11.31 %\n"
     ]
    }
   ],
   "source": [
    "print('Токсичных твитов во всем датасете', \n",
    "      round(100 * data.loc[data['toxic'] == 1].shape[0] / data.loc[data['toxic'] == 0].shape[0], 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистка, лемматизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_cleaned'] = data['text'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i am s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i cannot make any real suggestions on imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                        text_cleaned  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he matches this background colour i am s...  \n",
       "2  hey man i am really not trying to edit war it ...  \n",
       "3  more i cannot make any real suggestions on imp...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['text_lemmatized'] = data['text_cleaned'].apply(series_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_lemmatized'] = data['text_lemmatized'].apply(lambda text : ' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i am s...</td>\n",
       "      <td>d aww he match this background colour i am see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i cannot make any real suggestions on imp...</td>\n",
       "      <td>more i cannot make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>congratulations from me as well use the tools ...</td>\n",
       "      <td>congratulation from me a well use the tool wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry if the word nonsense was offensive to yo...</td>\n",
       "      <td>sorry if the word nonsense wa offensive to you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>fair use rationale for image wonju jpg thanks ...</td>\n",
       "      <td>fair use rationale for image wonju jpg thanks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>bbq be a man and lets discuss it maybe over th...</td>\n",
       "      <td>bbq be a man and let discus it maybe over the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>hey what is it talk what is it an exclusive gr...</td>\n",
       "      <td>hey what is it talk what is it an exclusive gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>before you start throwing accusations and warn...</td>\n",
       "      <td>before you start throwing accusation and warni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh and the girl above started her arguments wi...</td>\n",
       "      <td>oh and the girl above started her argument wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...</td>\n",
       "      <td>0</td>\n",
       "      <td>juelz santanas age in 2002 juelz santana was 1...</td>\n",
       "      <td>juelz santanas age in 2002 juelz santana wa 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>bye do not look come or think of comming back ...</td>\n",
       "      <td>bye do not look come or think of comming back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "      <td>redirect talk voydan pop georgiev chernodrinski</td>\n",
       "      <td>redirect talk voydan pop georgiev chernodrinski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Mitsurugi point made no sense - why not ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>the mitsurugi point made no sense why not argu...</td>\n",
       "      <td>the mitsurugi point made no sense why not argu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Don't mean to bother you \\n\\nI see that you're...</td>\n",
       "      <td>0</td>\n",
       "      <td>do not mean to bother you i see that you are w...</td>\n",
       "      <td>do not mean to bother you i see that you are w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic  \\\n",
       "0   Explanation\\nWhy the edits made under my usern...      0   \n",
       "1   D'aww! He matches this background colour I'm s...      0   \n",
       "2   Hey man, I'm really not trying to edit war. It...      0   \n",
       "3   \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4   You, sir, are my hero. Any chance you remember...      0   \n",
       "5   \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7   Your vandalism to the Matt Shirvington article...      0   \n",
       "8   Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9   alignment on this subject and which are contra...      0   \n",
       "10  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0   \n",
       "11  bbq \\n\\nbe a man and lets discuss it-maybe ove...      0   \n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1   \n",
       "13  Before you start throwing accusations and warn...      0   \n",
       "14  Oh, and the girl above started her arguments w...      0   \n",
       "15  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...      0   \n",
       "16  Bye! \\n\\nDon't look, come or think of comming ...      1   \n",
       "17   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski      0   \n",
       "18  The Mitsurugi point made no sense - why not ar...      0   \n",
       "19  Don't mean to bother you \\n\\nI see that you're...      0   \n",
       "\n",
       "                                         text_cleaned  \\\n",
       "0   explanation why the edits made under my userna...   \n",
       "1   d aww he matches this background colour i am s...   \n",
       "2   hey man i am really not trying to edit war it ...   \n",
       "3   more i cannot make any real suggestions on imp...   \n",
       "4   you sir are my hero any chance you remember wh...   \n",
       "5   congratulations from me as well use the tools ...   \n",
       "6        cocksucker before you piss around on my work   \n",
       "7   your vandalism to the matt shirvington article...   \n",
       "8   sorry if the word nonsense was offensive to yo...   \n",
       "9   alignment on this subject and which are contra...   \n",
       "10  fair use rationale for image wonju jpg thanks ...   \n",
       "11  bbq be a man and lets discuss it maybe over th...   \n",
       "12  hey what is it talk what is it an exclusive gr...   \n",
       "13  before you start throwing accusations and warn...   \n",
       "14  oh and the girl above started her arguments wi...   \n",
       "15  juelz santanas age in 2002 juelz santana was 1...   \n",
       "16  bye do not look come or think of comming back ...   \n",
       "17    redirect talk voydan pop georgiev chernodrinski   \n",
       "18  the mitsurugi point made no sense why not argu...   \n",
       "19  do not mean to bother you i see that you are w...   \n",
       "\n",
       "                                      text_lemmatized  \n",
       "0   explanation why the edits made under my userna...  \n",
       "1   d aww he match this background colour i am see...  \n",
       "2   hey man i am really not trying to edit war it ...  \n",
       "3   more i cannot make any real suggestion on impr...  \n",
       "4   you sir are my hero any chance you remember wh...  \n",
       "5   congratulation from me a well use the tool wel...  \n",
       "6        cocksucker before you piss around on my work  \n",
       "7   your vandalism to the matt shirvington article...  \n",
       "8   sorry if the word nonsense wa offensive to you...  \n",
       "9   alignment on this subject and which are contra...  \n",
       "10  fair use rationale for image wonju jpg thanks ...  \n",
       "11  bbq be a man and let discus it maybe over the ...  \n",
       "12  hey what is it talk what is it an exclusive gr...  \n",
       "13  before you start throwing accusation and warni...  \n",
       "14  oh and the girl above started her argument wit...  \n",
       "15  juelz santanas age in 2002 juelz santana wa 18...  \n",
       "16  bye do not look come or think of comming back ...  \n",
       "17    redirect talk voydan pop georgiev chernodrinski  \n",
       "18  the mitsurugi point made no sense why not argu...  \n",
       "19  do not mean to bother you i see that you are w...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   text             159292 non-null  object\n",
      " 1   toxic            159292 non-null  int64 \n",
      " 2   text_cleaned     159292 non-null  object\n",
      " 3   text_lemmatized  159292 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Разделение на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns = ['toxic'])\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, \n",
    "                                                                            target, \n",
    "                                                                            test_size = 0.25, \n",
    "                                                                            random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тестовой выборки: 39823\n",
      "Размер тренировочной выборки: 119469\n"
     ]
    }
   ],
   "source": [
    "print('Размер тестовой выборки:', features_test.shape[0])\n",
    "print('Размер тренировочной выборки:', features_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Балансировка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токсичных твитов в тренировочном датасете 11.313 %\n"
     ]
    }
   ],
   "source": [
    "print('Токсичных твитов в тренировочном датасете', \n",
    "      round(100 * target_train.loc[data['toxic'] == 1].shape[0] / target_train.loc[data['toxic'] == 0].shape[0], 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_upsampled, target_train_upsampled = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токсичных твитов в тренировочном датасете 45.252 %\n"
     ]
    }
   ],
   "source": [
    "print('Токсичных твитов в тренировочном датасете', \n",
    "      round(100 * target_train_upsampled.loc[data['toxic'] == 1].shape[0] / \n",
    "            target_train_upsampled.loc[data['toxic'] == 0].shape[0], 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk_stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер корпуса: (155895,)\n"
     ]
    }
   ],
   "source": [
    "corpus_lemmatized_train = features_train_upsampled['text_lemmatized'].values.astype('U')\n",
    "print('Размер корпуса:', corpus_lemmatized_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155895, 149683)\n"
     ]
    }
   ],
   "source": [
    "count_tf_idf = TfidfVectorizer (stop_words = stop_words)\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus_lemmatized_train)\n",
    "print(tf_idf_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер корпуса: (39823,)\n"
     ]
    }
   ],
   "source": [
    "corpus_lemmatized_test = features_test['text_lemmatized'].values\n",
    "print('Размер корпуса:', corpus_lemmatized_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39823, 149683)\n"
     ]
    }
   ],
   "source": [
    "tf_idf_test = count_tf_idf.transform(corpus_lemmatized_test)\n",
    "print(tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточый вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе подготовки данных из датасета был убран столбец unnamed. Для фильтрования разнообразных артефактов в тексте была написана функция text_cleaner, работающая с помощью регулярных выражений. Тексты лемматизированы с помощью NLTK wordnet. Около 11.313 % описаний обучающей выборки состоит из токсичных текстов, поэтому проведена балансировка классов с помощью upsampling. Рассчитаны TF-IDF для обучающей и тестовой выборок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'C': 15, 'max_iter': 50}\n",
      "Лучшая оценка: 0.9404879553773938\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logistic_regression_grid_space = {'C' : [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "                                  'max_iter' : [50, 100, 200]\n",
    "                                 }\n",
    "\n",
    "model_1 = LogisticRegression(random_state = 12345, solver = 'sag', class_weight = 'balanced')\n",
    "\n",
    "grid = GridSearchCV(estimator = model_1, param_grid = logistic_regression_grid_space, cv = 2, scoring = 'f1')\n",
    "model_grid = grid.fit(tf_idf_train, target_train_upsampled)\n",
    "\n",
    "print('Лучшие гиперпараметры:', model_grid.best_params_)\n",
    "print('Лучшая оценка:', abs(model_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=15, class_weight='balanced', max_iter=50,\n",
       "                   random_state=12345, solver='sag')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_1 = LogisticRegression(C = int(model_grid.best_params_['C']), \n",
    "                             max_iter = int(model_grid.best_params_['max_iter']), \n",
    "                             random_state = 12345, \n",
    "                             solver = 'sag', \n",
    "                             class_weight = 'balanced')\n",
    "model_1.fit(tf_idf_train, target_train_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
      "Лучшая оценка: 0.6466098088684222\n",
      "Wall time: 10min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "decision_tree_grid_space = {'max_depth' : [5, 10, 15],\n",
    "                            'min_samples_split' : [2, 4, 8],\n",
    "                            'min_samples_leaf' : [1, 2, 3]\n",
    "                           }\n",
    "\n",
    "model_2 = DecisionTreeClassifier(random_state = 12345, class_weight = 'balanced')\n",
    "\n",
    "grid = GridSearchCV(estimator = model_2, param_grid = decision_tree_grid_space, cv = 2, scoring = 'f1')\n",
    "model_grid = grid.fit(tf_idf_train, target_train_upsampled)\n",
    "\n",
    "print('Лучшие гиперпараметры:', model_grid.best_params_)\n",
    "print('Лучшая оценка:', abs(model_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
       "                       min_samples_split=4, random_state=12345)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_2 = DecisionTreeClassifier(max_depth = int(model_grid.best_params_['max_depth']), \n",
    "                                 min_samples_split = int(model_grid.best_params_['min_samples_split']),\n",
    "                                 min_samples_leaf = int(model_grid.best_params_['min_samples_leaf']),\n",
    "                                 random_state = 12345, \n",
    "                                 class_weight = 'balanced')\n",
    "model_2.fit(tf_idf_train, target_train_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'max_depth': 8, 'min_samples_leaf': 1, 'n_estimators': 400}\n",
      "Лучшая оценка: 0.6709660556799433\n",
      "Wall time: 23min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "random_forest_grid_space = {'n_estimators' : [10, 100, 200, 400],\n",
    "                            'max_depth' : [2, 4, 8],\n",
    "                            'min_samples_leaf' : [1, 2, 3]\n",
    "                           }\n",
    "\n",
    "model_3 = RandomForestClassifier(random_state = 12345, class_weight = 'balanced')\n",
    "\n",
    "grid = GridSearchCV(estimator = model_3, param_grid = random_forest_grid_space, cv = 2, scoring = 'f1')\n",
    "model_grid = grid.fit(tf_idf_train, target_train_upsampled)\n",
    "\n",
    "print('Лучшие гиперпараметры:', model_grid.best_params_)\n",
    "print('Лучшая оценка:', abs(model_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=8, n_estimators=400,\n",
       "                       random_state=12345)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_3 = RandomForestClassifier(n_estimators = int(model_grid.best_params_['n_estimators']), \n",
    "                                 max_depth = int(model_grid.best_params_['max_depth']),\n",
    "                                 min_samples_leaf = int(model_grid.best_params_['min_samples_leaf']),\n",
    "                                 random_state = 12345, \n",
    "                                 class_weight = 'balanced')\n",
    "model_3.fit(tf_idf_train, target_train_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Были протестированы три модели:\n",
    "- логистическая регрессия;\n",
    "- решающее дерево;\n",
    "- случайный лес.\n",
    "\n",
    "Результаты тренировки моделей в таблице ниже:\n",
    "\n",
    "|  |LogisticRegression|DecisionTreeClassifier|RandomForestClassifier| \n",
    "|:-|:-:|:-:|:-:|\n",
    "|F1|**0.940**|0.647|0.671|\n",
    "|Время обучения модели|0 мин 5.5 сек|0 мин 11.3 сек|0 мин 40.4 сек|\n",
    "|Время поиска гиперпараметров|2 мин 34 сек|10 мин 24 сек|23 мин 2 сек|\n",
    "\n",
    "Наилучшие результаты показала модель логистической регрессии с гиперпараметрами:\n",
    "- С = 15;\n",
    "- max_iter = 50;\n",
    "- solver = 'sag';\n",
    "- class_weight = 'balanced'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики наилучшей модели из исследованных:\n",
      "\n",
      "F1 = 0.765\n",
      "Wall time: 18.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predict_test = model_1.predict(tf_idf_test)\n",
    "\n",
    "print('Метрики наилучшей модели из исследованных:')                        \n",
    "print('\\nF1 =', round(f1_score(target_test, predict_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы над проектом была получена модель, определяющая токсичный или не токсичный текст описания. Тексты были отфильтрованы от разного рода артефактов (например выражений с апострофами), лемматизированы. Трненировочная выборка была сбалансирована с помощью upsampling.\n",
    "\n",
    "Наилучшей моделью оказалась LogisticRegression с гиперпараметрами:\n",
    "- С = 15;\n",
    "- max_iter = 50;\n",
    "- solver = 'sag';\n",
    "- class_weight = 'balanced'.\n",
    "\n",
    "Для наилучшей модели на тестовой выборке F1 = 0.765."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 48,
    "start_time": "2023-02-27T16:50:29.010Z"
   },
   {
    "duration": 428,
    "start_time": "2023-02-27T16:51:02.573Z"
   },
   {
    "duration": 2770,
    "start_time": "2023-02-27T16:51:03.004Z"
   },
   {
    "duration": 34,
    "start_time": "2023-02-27T16:51:05.776Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-27T16:51:05.812Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-27T16:51:05.826Z"
   },
   {
    "duration": 31,
    "start_time": "2023-02-27T16:51:05.846Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-27T16:51:05.878Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-27T16:51:46.943Z"
   },
   {
    "duration": 66,
    "start_time": "2023-02-27T16:52:21.530Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T16:52:24.926Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-27T16:52:25.635Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-27T16:59:47.739Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-27T16:59:55.277Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T16:59:56.321Z"
   },
   {
    "duration": 406,
    "start_time": "2023-02-27T17:00:56.140Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T17:01:48.686Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-27T17:01:49.463Z"
   },
   {
    "duration": 629,
    "start_time": "2023-02-27T17:02:45.675Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T17:02:46.307Z"
   },
   {
    "duration": 968,
    "start_time": "2023-02-27T17:02:46.313Z"
   },
   {
    "duration": 32,
    "start_time": "2023-02-27T17:02:47.283Z"
   },
   {
    "duration": 24,
    "start_time": "2023-02-27T17:02:47.318Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-27T17:02:47.343Z"
   },
   {
    "duration": 40,
    "start_time": "2023-02-27T17:02:47.355Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-27T17:02:47.397Z"
   },
   {
    "duration": 79360,
    "start_time": "2023-02-27T17:02:47.407Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-27T17:04:06.769Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-27T17:04:06.770Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-27T17:04:33.568Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-27T17:04:43.570Z"
   },
   {
    "duration": 158,
    "start_time": "2023-02-27T17:24:52.168Z"
   },
   {
    "duration": 894,
    "start_time": "2023-02-27T17:24:57.714Z"
   },
   {
    "duration": 510,
    "start_time": "2023-02-27T17:27:12.793Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-27T17:27:17.764Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-27T17:27:22.029Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T17:27:48.932Z"
   },
   {
    "duration": 80,
    "start_time": "2023-02-27T17:28:54.523Z"
   },
   {
    "duration": 43,
    "start_time": "2023-02-27T17:28:56.799Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T17:29:00.352Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-27T17:29:23.343Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-27T17:29:50.180Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T17:30:08.799Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-27T17:30:11.617Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
